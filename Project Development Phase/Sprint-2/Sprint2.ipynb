{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "y1nt9IyETliy",
        "outputId": "86468156-8c8b-4f53-e9b3-d49aebd66285"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-009dbfb850c4>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    cd//content/drive/MyDrive/Colab Notebooks/Dataset-20221108T081455Z-001/Dataset\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "ls\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "cd//content/drive/MyDrive/Colab Notebooks/Dataset-20221108T081455Z-001/Dataset\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "ls\n",
        "\n",
        "\n",
        "# **Import Neccessary Library**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "import numpy as np#used for numerical analysis\n",
        "import tensorflow #open source used for both ML and DL for computation\n",
        "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
        "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
        "#Dense layer is the regular deeply connected neural network layer\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "#Faltten-used fot flattening the input or change the dimension\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
        "#MaxPooling2D-for downsampling the image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# **Image Data Agumentation**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#setting parameter for Image Data agumentation to the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "#Image Data agumentation to the testing data\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# **Loading our data and performing data agumentation**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#performing data agumentation to train data\n",
        "x_train = train_datagen.flow_from_directory(\n",
        "    r'/content/drive/MyDrive/TRAIN_SET',\n",
        "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
        "#performing data agumentation to test data\n",
        "x_test = test_datagen.flow_from_directory(\n",
        "    r'/content/drive/MyDrive/TRAIN_SET',\n",
        "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') \n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "print(x_train.class_indices)#checking the number of classes\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "print(x_test.class_indices)#checking the number of classes\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "from collections import Counter as c\n",
        "c(x_train .labels)\n",
        "\n",
        "\n",
        "# **Creating the Model**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# Initializing the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# First convolution layer and pooling\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second convolution layer and pooling\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flattening the layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "classifier.summary()#summary of our model\n",
        "\n",
        "\n",
        "# **Compiling the Model**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# Compiling the CNN\n",
        "# categorical_crossentropy for more than 2\n",
        "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "\n",
        "# **Fitting the Model**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "classifier.fit_generator(\n",
        "        generator=x_train,steps_per_epoch = len(x_train),\n",
        "        epochs=10, validation_data=x_test,validation_steps = len(x_test))# No of images in test set\n",
        "\n",
        "\n",
        "# **Saving our Model**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# Save the model\n",
        "classifier.save('nutrition.h5')\n",
        "\n",
        "\n",
        "# **Nutrition Image Analysis using CNN**\n",
        "# ---\n",
        "# **Predicting our results**\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "img = image.load_img(\"/content/drive/MyDrive/TEST_SET/APPLES/n07740461_10080.jpg\",target_size= (64,64))#loading of the imageimg\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "x=image.img_to_array(img)#conversion image into array\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "x\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "x.ndim\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "x=np.expand_dims(x,axis=0) #expand the dimension\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "x.ndim\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "pred = classifier.predict(x)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "pred\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "labels=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
        "labels[np.argmax(pred)]\n"
      ]
    }
  ]
}